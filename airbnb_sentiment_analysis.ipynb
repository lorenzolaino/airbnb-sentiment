{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AirBnB Sentiment Analysis - Dataset generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Project Scope\n",
    " - Use of sentiment analysis, of the reviews of each ad, to view the evaluation of the ad\n",
    "    itself.\n",
    "\n",
    " - Search for relationships between the price of a room and the day of the week, holidays,\n",
    "    and time of year, and relationships between the price and the characteristics of a\n",
    "    room to make a forecast.\n",
    "\n",
    "Dataset: https://www.kaggle.com/brittabettendorf/berlin-airbnb-data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile36 as zipfile\n",
    "import langdetect\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import nltk\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Import of the reviews' dataset\n",
    "\n",
    "The first step concerns the download of the datasets.\n",
    "In particular, for this purpose, the Kaggle APIs are used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!kaggle datasets download -d brittabettendorf/berlin-airbnb-data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile('berlin-airbnb-data.zip')\n",
    "dfReviews = pd.read_csv(zf.open('reviews_summary.csv'))\n",
    "dfReviews.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Null data-points removal\n",
    "\n",
    "Once the dataset is available, it is needed to check whether there are some null data-points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfReviews.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfNullReviews = dfReviews[dfReviews['comments'].isnull()]\n",
    "print(f'Number of null comments: {dfNullReviews.shape[0]}')\n",
    "dfNullReviews.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfReviews.dropna(axis=0, how='any', inplace=True)\n",
    "dfReviews.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Lowercase conversion\n",
    "\n",
    "After the null data-points removal operation, it is needed to convert all the comments\n",
    "into lowercase strings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfReviews['comments'] = dfReviews.apply(lambda x: x['comments'].lower(), axis=1)\n",
    "dfReviews.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Reviews' language detection\n",
    "\n",
    "Since the comments are written in many languages, it can be useful to detect the language\n",
    "of each comment.\n",
    "This operation allows the selection of the comments based on their language (and also an\n",
    "eventual translation of all the comments into a common language).\n",
    "\n",
    "In order to detect the language of the comments, the langdetect library is used.\n",
    "\n",
    "The first step of this operation concerns the definition of a method that"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_lang_from_comment(dataframe):\n",
    "    list_langs = []\n",
    "    for index, comment in dataframe['comments'].iteritems():\n",
    "        if index % 5000 == 0:\n",
    "            print(f'Processed {index} rows...')\n",
    "        try:\n",
    "            comment_lang = langdetect.detect(comment[:50])\n",
    "            list_langs.append(comment_lang)\n",
    "        except:\n",
    "            list_langs.append(\"None\")\n",
    "\n",
    "    return list_langs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the language for each comment is detected, it is added as a new column to the already\n",
    "existing dataframe. Then the resulting dataframe is saved into a .csv file.\n",
    "\n",
    "Since this operation is very time-consuming, it is checked whether the operation has\n",
    "already been executed, and the results have been saved into a .csv file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.exists('reviews_summary_langs.csv'):\n",
    "    dfReviews = pd.read_csv('reviews_summary_langs.csv')\n",
    "else:\n",
    "    dfReviews['Lang'] = get_lang_from_comment(dfReviews)\n",
    "    dfReviews.to_csv('reviews_summary_langs.csv', sep=\",\", index=False, header=True)\n",
    "\n",
    "dfReviews.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfReviews['Lang'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The rows in which the 'Lang' column shows the value 'None' are the ones that in the previous\n",
    "step have thrown some problems.\n",
    "In particular, the possible problems are the inability of the used technique to detect\n",
    "their language or the too-narrow length of the review."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfNoneLangReviews = dfReviews[dfReviews['Lang'] == 'None']\n",
    "print(f'Number of reviews with None language: {dfNoneLangReviews.shape[0]}')\n",
    "print(f'Percentage of reviews with None language: '\n",
    "      f'{round(dfNoneLangReviews.shape[0] * 100 / dfReviews.shape[0],2)}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.1 English reviews selection\n",
    "\n",
    "The reviews written in english language are the interesting ones for this analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfEnglishReviews = dfReviews[dfReviews['Lang'] == 'en']\n",
    "dfEnglishReviews.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfEnglishReviews.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Duplicates removal\n",
    "\n",
    "Another required step is the removal of the duplicated reviews."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Number of English reviews: {}'.format(dfEnglishReviews.shape[0]))\n",
    "print('Number of unique English reviews: {}'.format(len(dfEnglishReviews['comments'].unique())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfEnglishReviews = dfEnglishReviews.drop_duplicates(subset='comments')\n",
    "print(f'Number of reviews after the duplicated removal: {dfEnglishReviews.shape[0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5 Non-English words removal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfEnglishReviews['comments'].iloc[172]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from re import sub\n",
    "\n",
    "dfEnglishReviews['comments'] = dfEnglishReviews.apply(\n",
    "    lambda x: sub(r\"[^A-Za-z]\", \" \", x['comments']), axis=1)\n",
    "dfEnglishReviews['comments'].iloc[172]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.6 Tokenization\n",
    "\n",
    "In order to prepare the data for the analysis model, it is needed to perform a tokenization\n",
    "operation.\n",
    "For this purpose, the 'gensim' library is used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizedEnglishReviews = dfEnglishReviews.apply(\n",
    "    lambda x: gensim.utils.simple_preprocess(str(x['comments'])), axis=1)\n",
    "tokenizedEnglishReviews"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.7 Normalization\n",
    "\n",
    "Another important step concerns the normalization of the reviews.\n",
    "For this purpose, the 'nltk' library is used.\n",
    "\n",
    "In particular, the 'wordnet' and 'average_perceptron_tagger' packages are downloaded from\n",
    "the 'nltk' resources.\n",
    "The first package provides a 'Lemmatizer' that, given a word, converts it into its base form.\n",
    "The second package provides a method that, given a word, returns a tag representing its\n",
    "grammatical type."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "def lemmatize_reviews(tokenized_reviews):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_reviews = []\n",
    "    for tokens_review in tokenized_reviews:\n",
    "        lemmatized_review = []\n",
    "        for word, tag in pos_tag(tokens_review):\n",
    "            if tag.startswith('NN'):\n",
    "                pos = 'n'\n",
    "            elif tag.startswith('VB'):\n",
    "                pos = 'v'\n",
    "            else:\n",
    "                pos = 'a'\n",
    "            lemmatized_review.append(lemmatizer.lemmatize(word, pos))\n",
    "        lemmatized_reviews.append(lemmatized_review)\n",
    "\n",
    "    return lemmatized_reviews"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lemmatizedTokenizedEnglishReviews = lemmatize_reviews(tokenizedEnglishReviews)\n",
    "lemmatizedTokenizedEnglishReviews[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Sentiment Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The idea of the sentiment analysis is to determine whether the reviews, of Airbnb\n",
    "activity in Berlin, are positive or negative."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Bigrams generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to take into account some small sequences of words the bigrams are introduced.\n",
    "The Gensim Phrases package is used to automatically detect bigrams from a list\n",
    "of sentences."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "phrases = Phrases(lemmatizedTokenizedEnglishReviews, min_count=3, progress_per=50000)\n",
    "\n",
    "bigram = Phraser(phrases)\n",
    "\n",
    "bigramReviews = bigram[lemmatizedTokenizedEnglishReviews]\n",
    "\n",
    "bigramReviews[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dictWordFreq = defaultdict(int)\n",
    "for review in bigramReviews:\n",
    "    for i in review:\n",
    "        dictWordFreq[i] += 1\n",
    "\n",
    "len(dictWordFreq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted(dictWordFreq, key=dictWordFreq.get, reverse=True)[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Word2Vec model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Word2Vec is a group of models that tries to represent each word in a large text as\n",
    "a vector in a space of N dimensions (which we will call features) making similar\n",
    "words also be close to each other.\n",
    "In this particular case the CBOW architecture is used.\n",
    "In this way, each word in the corpus is predicted by its given context."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from time import time\n",
    "\n",
    "if os.path.exists('word2vec.model'):\n",
    "    w2vModel = Word2Vec.load('word2vec.model')\n",
    "else:\n",
    "    w2vModel = Word2Vec(min_count=20,\n",
    "                        window=4,\n",
    "                        vector_size=300,\n",
    "                        sample=6e-5,\n",
    "                        alpha=0.03,\n",
    "                        min_alpha=0.0007,\n",
    "                        negative=20,\n",
    "                        workers=4)\n",
    "\n",
    "    t = time()\n",
    "    w2vModel.build_vocab(bigramReviews, progress_per=10000)\n",
    "    print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "    t = time()\n",
    "    w2vModel.train(bigramReviews,\n",
    "                   total_examples=w2vModel.corpus_count,\n",
    "                   epochs=30,\n",
    "                   report_delay=1)\n",
    "    print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "    w2vModel.save(\"word2vec.model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As an example, it is possible to show the most similar words to a given word.\n",
    "This step allows to have a first look at the goodness of the Word2Vec model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2vModel.wv.most_similar(positive=[\"apartment\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Clustering model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the clustering, the K-means technique is used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "kmeansModel2Clusters = KMeans(n_clusters=2, max_iter=1000, random_state=42, n_init=50)\n",
    "kmeansModel2Clusters.fit(X=w2vModel.wv.vectors.astype('double'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to check which cluster is relatively positive, and which negative, it is\n",
    "possible to show the words that are the nearest to each cluster.\n",
    "In particular, the cosine similarity to the coordinates of first cluster is used\n",
    "to determine the similarity between cluster and word."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2vModel.wv.similar_by_vector(kmeansModel2Clusters.cluster_centers_[0],\n",
    "                              topn=10,\n",
    "                              restrict_vocab=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The 10 closest words to cluster number 0 in terms of cosine distance are shown.\n",
    "Looking at these words, it is possible to state that the cluster 0 is the cluster\n",
    "concerning the negative words."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "negativeClusterIndex = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next step concerns the assignment to each word of the sentiment score, computed\n",
    "through its converted cluster value, negative (-1) or positive (1), and its closeness\n",
    "score, that simply represents the closeness of a word to its cluster center."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfWords2Clusters = pd.DataFrame(\n",
    "    w2vModel.wv.key_to_index.keys())\n",
    "\n",
    "dfWords2Clusters.columns = ['words']\n",
    "\n",
    "dfWords2Clusters['vectors'] = \\\n",
    "    dfWords2Clusters['words'].apply(\n",
    "        lambda x: w2vModel.wv[f'{x}'])\n",
    "\n",
    "dfWords2Clusters['cluster'] = \\\n",
    "    dfWords2Clusters['vectors'].apply(\n",
    "        lambda x: kmeansModel2Clusters.predict([np.array(x)]))\n",
    "\n",
    "dfWords2Clusters['cluster'] = \\\n",
    "    dfWords2Clusters['cluster'].apply(\n",
    "        lambda x: x[0])\n",
    "\n",
    "dfWords2Clusters.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfWords2Clusters['cluster_value'] = [\n",
    "    -1 if i==negativeClusterIndex else 1\n",
    "    for i in dfWords2Clusters['cluster']]\n",
    "\n",
    "dfWords2Clusters['closeness_score'] = \\\n",
    "    dfWords2Clusters.apply(\n",
    "        lambda x: 1/(kmeansModel2Clusters.transform([x.vectors]).min()),\n",
    "        axis=1)\n",
    "\n",
    "dfWords2Clusters['sentiment_coeff'] = \\\n",
    "    dfWords2Clusters['closeness_score'] * \\\n",
    "    dfWords2Clusters['cluster_value']\n",
    "\n",
    "dfWords2Clusters[\n",
    "    dfWords2Clusters['cluster_value'] == -1].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the above steps, a full dataframe of words is created,\n",
    "where each word has its own weighted cluster value, closeness score and sentiment\n",
    "score."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4 TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TF-IDF is used to show how important a word is to a review."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfCleanedReviews = pd.DataFrame(\n",
    "    [' '.join(review) for review in lemmatizedTokenizedEnglishReviews],\n",
    "    columns=['comments'])\n",
    "\n",
    "dfCleanedReviews.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To calculate the tfidf score of each word, the sklearn library is used.\n",
    "This step is conducted to consider how unique every word is for every sentence,\n",
    "and increase positive/negative signal associated with words that are highly specific\n",
    "for given sentence in comparison to whole corpus."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(norm=None)\n",
    "transformed = tfidf.fit_transform(\n",
    "    dfCleanedReviews['comments'].tolist())\n",
    "features = pd.Series(tfidf.get_feature_names())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, a vector containing the tfidf score for each review is created by replacing\n",
    "each word with the corresponding tfidf score."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features_file):\n",
    "    \"\"\"\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "\n",
    "    inspired  by function from this wonderful article:\n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    \"\"\"\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features_file.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features_file):\n",
    "    \"\"\"\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    \"\"\"\n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features_file)\n",
    "    try:\n",
    "        res = list(map(lambda y:dictionary[f'{y}'], x['comments'].split()))\n",
    "    except KeyError:\n",
    "        res = [0 for i in x['comments'].split()]\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tfidfScores = dfCleanedReviews.apply(\n",
    "    lambda x: replace_tfidf_words(x, transformed, features), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.5 Closeness score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the TF-IDF score, each word in every sentence is replaced by its own\n",
    "closeness score."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dictSentiment2Clusters = dict(zip(\n",
    "    dfWords2Clusters['words'].values,\n",
    "    dfWords2Clusters['sentiment_coeff'].values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    \"\"\"\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    \"\"\"\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "closenessScores2Clusters = \\\n",
    "    dfCleanedReviews['comments'].apply(\n",
    "        lambda x: list(map(\n",
    "            lambda y: replace_sentiment_words(y, dictSentiment2Clusters),\n",
    "            x.split())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.6 Sentiment score computation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A new dataframe is created by associating all the preivously-obtained values with\n",
    "each review."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfSentiment2ClustersTfidfReviews = \\\n",
    "    pd.DataFrame([closenessScores2Clusters,\n",
    "                  tfidfScores,\n",
    "                  dfCleanedReviews['comments']]).T\n",
    "\n",
    "dfSentiment2ClustersTfidfReviews.columns = \\\n",
    "    ['sentiment_coeff', 'tfidf_scores', 'review']\n",
    "\n",
    "dfSentiment2ClustersTfidfReviews['sentiment_rate'] = \\\n",
    "    dfSentiment2ClustersTfidfReviews.apply(\n",
    "        lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']),\n",
    "        axis=1)\n",
    "\n",
    "dfSentiment2ClustersTfidfReviews['prediction'] =\\\n",
    "    (dfSentiment2ClustersTfidfReviews['sentiment_rate'] > 0)\\\n",
    "        .astype('int8')\n",
    "\n",
    "dfSentiment2ClustersTfidfReviews.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is also possible to show as an example the top-5 negative reviews, according to\n",
    "our sentiment prediction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfNegativeSentiment = dfSentiment2ClustersTfidfReviews[\n",
    "    dfSentiment2ClustersTfidfReviews['prediction'] == 0].sort_values(\n",
    "        by=['sentiment_rate'])\n",
    "\n",
    "print('Top-5 negative reviews:')\n",
    "dfNegativeSentiment['review'].head().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, the dataset can be saved into a .csv file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dfSentiment2ClustersTfidfReviews.to_csv(\n",
    "#     'sentiment_dataset_2_clusters.csv',\n",
    "#     sep=',', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.7 TextBlob"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to understand the goodness of the obtained results, they can be compared to\n",
    "the ones obtained by an already-existing external library.\n",
    "In particular the TextBlob library is used, which is built on the shoulders of NLTK."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For each review, the sentiment score is computed by using TextBlob."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "textblobSentiment = dfCleanedReviews['comments'].apply(\n",
    "    lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "textblobSentiment.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The TextBlob sentiment score is associated with each review."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfSentiment2ClustersTfidfReviews['textblob_sentiment'] = \\\n",
    "    textblobSentiment\n",
    "\n",
    "dfSentiment2ClustersTfidfReviews['textblob_prediction'] = \\\n",
    "    (dfSentiment2ClustersTfidfReviews['textblob_sentiment'] > 0)\\\n",
    "        .astype('int8')\n",
    "\n",
    "dfSentiment2ClustersTfidfReviews.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.8 Sentiment Analysis Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, it is possible to compare the obtained results by using the accuracy metrics.\n",
    "In particular, the Textblob results are used as truth labels, and the\n",
    "manually-obtained results are used as predictions.\n",
    "Even in this case, the sklearn library is used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_test_scores(predictions, labels):\n",
    "\n",
    "    df_conf_matrix = pd.DataFrame(confusion_matrix(labels, predictions))\n",
    "\n",
    "    print(df_conf_matrix)\n",
    "\n",
    "    test_scores = accuracy_score(labels, predictions), \\\n",
    "                  precision_score(labels, predictions), \\\n",
    "                  recall_score(labels, predictions), \\\n",
    "                  f1_score(labels, predictions)\n",
    "\n",
    "    return test_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testScores2ClustersSentiment = compute_test_scores(\n",
    "    dfSentiment2ClustersTfidfReviews['prediction'],\n",
    "    dfSentiment2ClustersTfidfReviews['textblob_prediction'])\n",
    "\n",
    "dfTestScores2ClustersSentiment = pd.DataFrame([testScores2ClustersSentiment])\n",
    "dfTestScores2ClustersSentiment.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "dfTestScores2ClustersSentiment = dfTestScores2ClustersSentiment.T\n",
    "dfTestScores2ClustersSentiment.columns = ['scores']\n",
    "\n",
    "print('Scores for sentiment analysis with 2 clusters and no stopwords: ')\n",
    "dfTestScores2ClustersSentiment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The sentiment analysis with 2 clusters shows bad results.\n",
    "So, it is possible to use both the elbow and the silhouette methods in order to check\n",
    "whether the clustering of the words can be performed with better results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.9 Clustering evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Elbow Method is used to find the best value of the number of cluster."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def kmeans_elbow_method(vectors):\n",
    "    wcss = []\n",
    "    for i in range(1, 11):\n",
    "        kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
    "        kmeans.fit(X=vectors)\n",
    "\n",
    "        # inertia_ is sum of squared distance of samples to its closest cluster centers.\n",
    "        wcss.append(kmeans.inertia_)\n",
    "        print(\"inertia_\", kmeans.inertia_)\n",
    "\n",
    "    plt.plot(range(1, 11), wcss)\n",
    "    plt.title('Elbow Method')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans_elbow_method(w2vModel.wv.vectors.astype('double'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the above Elbow method plot is not easy to establish a definitive value of\n",
    "number of clusters.\n",
    "So, in order to be more precise, the Silhouette method can be useful to understand\n",
    "the right number of cluster."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def kmeans_silhouette(x,range_clusters):\n",
    "    for i, k in range_clusters :\n",
    "\n",
    "        # Run the Kmeans algorithm\n",
    "        km = KMeans(n_clusters = k, init = 'k-means++', random_state = 42)\n",
    "\n",
    "        km.fit(x)\n",
    "        labels = km.predict(x)\n",
    "\n",
    "        print(\"For n_clusters =\", k,\n",
    "                  \"The computed average silhouette_score is :\",\n",
    "              silhouette_score(x, labels, metric='euclidean'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rangeClusters = enumerate([2,3,4,5,6,7,8,9,10])\n",
    "kmeans_silhouette(w2vModel.wv.vectors.astype('double'), rangeClusters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The obtained value show that the clustering with n_clusters = 3 could perform better\n",
    "results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Sentiment analysis with 3 clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The performed steps are the same of the previous analysis.\n",
    "The steps concerning Word2Vec, TF-IDF and TextBlob are not applied because the\n",
    "results would be the same with respect to the previous ones."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 Clustering model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeansModel3Clusters = KMeans(n_clusters=3, max_iter=1000, random_state=42, n_init=50)\n",
    "kmeansModel3Clusters.fit(X=w2vModel.wv.vectors.astype('double'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2vModel.wv.similar_by_vector(\n",
    "    kmeansModel3Clusters.cluster_centers_[2], topn=10, restrict_vocab=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "negativeClusterIndex = 2\n",
    "positiveClusterIndex = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfWords3Clusters = pd.DataFrame(\n",
    "    w2vModel.wv.key_to_index.keys())\n",
    "\n",
    "dfWords3Clusters.columns = ['words']\n",
    "\n",
    "dfWords3Clusters['vectors'] = \\\n",
    "    dfWords3Clusters['words'].apply(\n",
    "        lambda x: w2vModel.wv[f'{x}'])\n",
    "\n",
    "dfWords3Clusters['cluster'] = \\\n",
    "    dfWords3Clusters['vectors'].apply(\n",
    "        lambda x: kmeansModel3Clusters.predict([np.array(x)]))\n",
    "\n",
    "dfWords3Clusters.cluster = \\\n",
    "    dfWords3Clusters['cluster'].apply(\n",
    "        lambda x: x[0])\n",
    "\n",
    "dfWords3Clusters.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfWords3Clusters['cluster_value'] = \\\n",
    "    [-1 if i==negativeClusterIndex\n",
    "     else 1 if i==positiveClusterIndex else 0\n",
    "     for i in dfWords3Clusters['cluster']]\n",
    "\n",
    "dfWords3Clusters['closeness_score'] = \\\n",
    "    dfWords3Clusters.apply(\n",
    "        lambda x: 1/(kmeansModel3Clusters.transform([x.vectors]).min()),\n",
    "        axis=1)\n",
    "\n",
    "dfWords3Clusters['sentiment_coeff'] = \\\n",
    "    dfWords3Clusters['closeness_score'] * \\\n",
    "    dfWords3Clusters['cluster_value']\n",
    "\n",
    "dfWords3Clusters[\n",
    "    dfWords3Clusters['cluster_value'] == -1].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Closeness score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dictSentiment3Clusters = dict(zip(\n",
    "    dfWords3Clusters['words'].values,\n",
    "    dfWords3Clusters['sentiment_coeff'].values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "closenessScores3Clusters = \\\n",
    "    dfCleanedReviews['comments'].apply(\n",
    "        lambda x: list(map(\n",
    "            lambda y: replace_sentiment_words(y, dictSentiment3Clusters),\n",
    "            x.split())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Sentiment score computation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfSentiment3ClustersTfidfReviews = pd.DataFrame(\n",
    "    [closenessScores3Clusters,\n",
    "     tfidfScores,\n",
    "     dfCleanedReviews['comments']]).T\n",
    "\n",
    "dfSentiment3ClustersTfidfReviews.columns = \\\n",
    "    ['sentiment_coeff', 'tfidf_scores', 'review']\n",
    "\n",
    "dfSentiment3ClustersTfidfReviews['sentiment_rate'] = \\\n",
    "    dfSentiment3ClustersTfidfReviews.apply(\n",
    "        lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']),\n",
    "        axis=1)\n",
    "\n",
    "dfSentiment3ClustersTfidfReviews['prediction'] = \\\n",
    "    (dfSentiment3ClustersTfidfReviews['sentiment_rate']>0)\\\n",
    "        .astype('int8')\n",
    "\n",
    "dfSentiment3ClustersTfidfReviews.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dfSentiment3ClustersTfidfReviews.to_csv(\n",
    "#     'sentiment_dataset_3_clusters.csv',\n",
    "#     sep=',', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfNegativeSentiment = dfSentiment3ClustersTfidfReviews[\n",
    "    dfSentiment3ClustersTfidfReviews['prediction'] == 0].sort_values(\n",
    "        by=['sentiment_rate'])\n",
    "\n",
    "dfNegativeSentiment['review'].head().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4 TextBlob"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfSentiment3ClustersTfidfReviews['textblob_sentiment'] = \\\n",
    "    textblobSentiment\n",
    "\n",
    "dfSentiment3ClustersTfidfReviews['textblob_prediction'] = \\\n",
    "    (dfSentiment3ClustersTfidfReviews['textblob_sentiment'] > 0)\\\n",
    "        .astype('int8')\n",
    "\n",
    "dfSentiment3ClustersTfidfReviews.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.5 Sentiment analysis evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testScores3ClustersSentiment = compute_test_scores(\n",
    "    dfSentiment3ClustersTfidfReviews['prediction'],\n",
    "    dfSentiment3ClustersTfidfReviews['textblob_prediction'])\n",
    "\n",
    "dfTestScores3ClustersSentiment = pd.DataFrame([testScores3ClustersSentiment])\n",
    "dfTestScores3ClustersSentiment.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "dfTestScores3ClustersSentiment = dfTestScores3ClustersSentiment.T\n",
    "dfTestScores3ClustersSentiment.columns = ['scores']\n",
    "\n",
    "print('Scores for sentiment analysis with 3 clusters and no stopwords: ')\n",
    "dfTestScores3ClustersSentiment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The sentiment analysis with 3 clusters shows better results compared to the\n",
    "sentiment analysis with 2 clusters.\n",
    "However, it could be interesting to investigate the results that can be obtained by\n",
    "removing the stop words."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Sentiment Analysis without stop words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The performed steps are the same as before."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1 Stop words removal\n",
    "\n",
    "In order to obtain a list of the English common stop words, the 'stopwords'\n",
    "package of the 'nltk' library is used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopWords = stopwords.words('english')\n",
    "stopWords[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_stop_words(tokenized_reviews, stop_words):\n",
    "    tokenized_reviews_without_stopwords = []\n",
    "    for tokenized_review in tokenized_reviews:\n",
    "        tokenized_reviews_without_stopwords.append(\n",
    "            [word for word in tokenized_review if not word in stop_words]\n",
    "        )\n",
    "    return tokenized_reviews_without_stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lemmatizedTokenizedEnglishReviewsWithoutStopWords = remove_stop_words(\n",
    "    lemmatizedTokenizedEnglishReviews, stopWords)\n",
    "lemmatizedTokenizedEnglishReviewsWithoutStopWords[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2 Bigrams generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "phrasesWithoutStopWords = Phrases(lemmatizedTokenizedEnglishReviewsWithoutStopWords,\n",
    "                                  min_count=3,\n",
    "                                  progress_per=50000)\n",
    "\n",
    "bigramWithoutStopWords = Phraser(phrasesWithoutStopWords)\n",
    "\n",
    "bigramReviewsWithoutStopWords = bigramWithoutStopWords[\n",
    "    lemmatizedTokenizedEnglishReviewsWithoutStopWords]\n",
    "\n",
    "bigramReviewsWithoutStopWords[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dictWordFreq = defaultdict(int)\n",
    "for review in bigramReviewsWithoutStopWords:\n",
    "    for i in review:\n",
    "        dictWordFreq[i] += 1\n",
    "\n",
    "len(dictWordFreq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted(dictWordFreq, key=dictWordFreq.get, reverse=True)[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3 Word2Vec model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.exists('word2vec_no_stopwords.model'):\n",
    "    w2vModelWithoutStopWords = Word2Vec.load('word2vec_no_stopwords.model')\n",
    "else:\n",
    "    w2vModelWithoutStopWords = Word2Vec(min_count=20,\n",
    "                                 window=4,\n",
    "                                 vector_size=300,\n",
    "                                 sample=6e-5,\n",
    "                                 alpha=0.03,\n",
    "                                 min_alpha=0.0007,\n",
    "                                 negative=20,\n",
    "                                 workers=4)\n",
    "\n",
    "    t = time()\n",
    "    w2vModelWithoutStopWords.build_vocab(bigramReviewsWithoutStopWords, progress_per=10000)\n",
    "    print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "    t = time()\n",
    "    w2vModelWithoutStopWords.train(bigramReviewsWithoutStopWords,\n",
    "                                   total_examples=w2vModelWithoutStopWords.corpus_count,\n",
    "                                   epochs=30,\n",
    "                                   report_delay=1)\n",
    "    print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "    w2vModelWithoutStopWords.save(\"word2vec_no_stopwords.model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2vModelWithoutStopWords.wv.most_similar(positive=[\"apartment\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.4 Clustering model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeansModel2Clusters = KMeans(n_clusters=2, max_iter=1000, random_state=42, n_init=50)\n",
    "kmeansModel2Clusters.fit(X=w2vModelWithoutStopWords.wv.vectors.astype('double'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2vModelWithoutStopWords.wv.similar_by_vector(kmeansModel2Clusters.cluster_centers_[0],\n",
    "                                              topn=10,\n",
    "                                              restrict_vocab=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "negativeClusterIndex = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfWords2ClustersWithoutStopWords = pd.DataFrame(\n",
    "    w2vModelWithoutStopWords.wv.key_to_index.keys())\n",
    "\n",
    "dfWords2ClustersWithoutStopWords.columns = ['words']\n",
    "\n",
    "dfWords2ClustersWithoutStopWords['vectors'] = \\\n",
    "    dfWords2ClustersWithoutStopWords['words'].apply(\n",
    "        lambda x: w2vModelWithoutStopWords.wv[f'{x}'])\n",
    "\n",
    "dfWords2ClustersWithoutStopWords['cluster'] = \\\n",
    "    dfWords2ClustersWithoutStopWords['vectors'].apply(\n",
    "        lambda x: kmeansModel2Clusters.predict([np.array(x)]))\n",
    "\n",
    "dfWords2ClustersWithoutStopWords['cluster'] = \\\n",
    "    dfWords2ClustersWithoutStopWords['cluster'].apply(\n",
    "        lambda x: x[0])\n",
    "\n",
    "dfWords2ClustersWithoutStopWords.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfWords2ClustersWithoutStopWords['cluster_value'] = [\n",
    "    -1 if i==negativeClusterIndex else 1\n",
    "    for i in dfWords2ClustersWithoutStopWords['cluster']]\n",
    "\n",
    "dfWords2ClustersWithoutStopWords['closeness_score'] = \\\n",
    "    dfWords2ClustersWithoutStopWords.apply(\n",
    "        lambda x: 1/(kmeansModel2Clusters.transform([x.vectors]).min()),\n",
    "        axis=1)\n",
    "\n",
    "dfWords2ClustersWithoutStopWords['sentiment_coeff'] = \\\n",
    "    dfWords2ClustersWithoutStopWords['closeness_score'] * \\\n",
    "    dfWords2ClustersWithoutStopWords['cluster_value']\n",
    "\n",
    "dfWords2ClustersWithoutStopWords[\n",
    "    dfWords2ClustersWithoutStopWords['cluster_value'] == -1].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.5 TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfCleanedReviewsWithoutStopWords = pd.DataFrame(\n",
    "    [' '.join(review) for review in lemmatizedTokenizedEnglishReviewsWithoutStopWords],\n",
    "    columns=['comments'])\n",
    "\n",
    "dfCleanedReviewsWithoutStopWords.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tfidfWithoutStopWords = TfidfVectorizer(norm=None)\n",
    "transformed = tfidfWithoutStopWords.fit_transform(\n",
    "    dfCleanedReviewsWithoutStopWords['comments'].tolist())\n",
    "features = pd.Series(tfidfWithoutStopWords.get_feature_names())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tfidfScoresWithoutStopWords = dfCleanedReviewsWithoutStopWords.apply(\n",
    "    lambda x: replace_tfidf_words(x, transformed, features), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.6 Closeness score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dictSentiment2ClustersWithoutStopWords = dict(zip(\n",
    "    dfWords2ClustersWithoutStopWords['words'].values,\n",
    "    dfWords2ClustersWithoutStopWords['sentiment_coeff'].values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "closenessScores2ClustersWithoutStopWords = \\\n",
    "    dfCleanedReviewsWithoutStopWords['comments'].apply(\n",
    "        lambda x: list(map(\n",
    "            lambda y: replace_sentiment_words(y, dictSentiment2ClustersWithoutStopWords),\n",
    "            x.split())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.7 Sentiment score computation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfSentiment2ClustersTfidfReviewsWithoutStopWords = \\\n",
    "    pd.DataFrame([closenessScores2ClustersWithoutStopWords,\n",
    "                  tfidfScoresWithoutStopWords,\n",
    "                  dfCleanedReviewsWithoutStopWords['comments']]).T\n",
    "\n",
    "dfSentiment2ClustersTfidfReviewsWithoutStopWords.columns = \\\n",
    "    ['sentiment_coeff', 'tfidf_scores', 'review']\n",
    "\n",
    "dfSentiment2ClustersTfidfReviewsWithoutStopWords['sentiment_rate'] = \\\n",
    "    dfSentiment2ClustersTfidfReviewsWithoutStopWords.apply(\n",
    "        lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']),\n",
    "        axis=1)\n",
    "\n",
    "dfSentiment2ClustersTfidfReviewsWithoutStopWords['prediction'] =\\\n",
    "    (dfSentiment2ClustersTfidfReviewsWithoutStopWords['sentiment_rate'] > 0)\\\n",
    "        .astype('int8')\n",
    "\n",
    "dfSentiment2ClustersTfidfReviewsWithoutStopWords.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfNegativeSentiment = dfSentiment2ClustersTfidfReviewsWithoutStopWords[\n",
    "    dfSentiment2ClustersTfidfReviewsWithoutStopWords['prediction'] == 0].sort_values(\n",
    "        by=['sentiment_rate'])\n",
    "\n",
    "print('Top-5 negative reviews:')\n",
    "dfNegativeSentiment['review'].head().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dfSentiment2ClustersTfidfReviewsWithoutStopWords.to_csv(\n",
    "#     'sentiment_dataset_2_clusters_no_stopwords.csv',\n",
    "#     sep=',', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.8 TextBlob"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "textblobSentimentWithoutStopWords = dfCleanedReviewsWithoutStopWords['comments'].apply(\n",
    "    lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "textblobSentimentWithoutStopWords.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfSentiment2ClustersTfidfReviewsWithoutStopWords['textblob_sentiment'] = \\\n",
    "    textblobSentimentWithoutStopWords\n",
    "\n",
    "dfSentiment2ClustersTfidfReviewsWithoutStopWords['textblob_prediction'] = \\\n",
    "    (dfSentiment2ClustersTfidfReviewsWithoutStopWords['textblob_sentiment'] > 0)\\\n",
    "        .astype('int8')\n",
    "\n",
    "dfSentiment2ClustersTfidfReviewsWithoutStopWords.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.9 Sentiment analysis evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testScores2ClustersWithoutStopWordsSentiment = compute_test_scores(\n",
    "    dfSentiment2ClustersTfidfReviewsWithoutStopWords['prediction'],\n",
    "    dfSentiment2ClustersTfidfReviewsWithoutStopWords['textblob_prediction'])\n",
    "\n",
    "dfTestScores2ClustersWithoutStopWordsSentiment = pd.DataFrame(\n",
    "    [testScores2ClustersWithoutStopWordsSentiment])\n",
    "\n",
    "dfTestScores2ClustersWithoutStopWordsSentiment.columns = \\\n",
    "    ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "dfTestScores2ClustersWithoutStopWordsSentiment = \\\n",
    "    dfTestScores2ClustersWithoutStopWordsSentiment.T\n",
    "\n",
    "dfTestScores2ClustersWithoutStopWordsSentiment.columns = ['scores']\n",
    "\n",
    "print('Scores for sentiment analysis with 2 clusters and no stopwords: ')\n",
    "dfTestScores2ClustersWithoutStopWordsSentiment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The obtained results seem to be very good.\n",
    "Even in this case it is possible to check whether there exists a better value for the\n",
    "number of cluster."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.10 Clustering evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans_elbow_method(w2vModelWithoutStopWords.wv.vectors.astype('double'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rangeClusters = enumerate([2,3,4,5,6,7,8,9,10])\n",
    "kmeans_silhouette(w2vModelWithoutStopWords.wv.vectors.astype('double'), rangeClusters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even if the Silhouette method shows a worse score with n_clusters = 3, it can be\n",
    "interesting to check how much the model accuracy changes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Sentiment analysis without stop words with 3 clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The performed steps are the same as before."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1 Clustering model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeansModel3Clusters = KMeans(n_clusters=3, max_iter=1000, random_state=42, n_init=50)\n",
    "kmeansModel3Clusters.fit(X=w2vModelWithoutStopWords.wv.vectors.astype('double'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2vModelWithoutStopWords.wv.similar_by_vector(\n",
    "    kmeansModel3Clusters.cluster_centers_[2], topn=10, restrict_vocab=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "negativeClusterIndex = 2\n",
    "positiveClusterIndex = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfWords3ClustersWithoutStopWords = pd.DataFrame(\n",
    "    w2vModelWithoutStopWords.wv.key_to_index.keys())\n",
    "\n",
    "dfWords3ClustersWithoutStopWords.columns = ['words']\n",
    "\n",
    "dfWords3ClustersWithoutStopWords['vectors'] = \\\n",
    "    dfWords3ClustersWithoutStopWords['words'].apply(\n",
    "        lambda x: w2vModelWithoutStopWords.wv[f'{x}'])\n",
    "\n",
    "dfWords3ClustersWithoutStopWords['cluster'] = \\\n",
    "    dfWords3ClustersWithoutStopWords['vectors'].apply(\n",
    "        lambda x: kmeansModel3Clusters.predict([np.array(x)]))\n",
    "\n",
    "dfWords3ClustersWithoutStopWords.cluster = \\\n",
    "    dfWords3ClustersWithoutStopWords['cluster'].apply(\n",
    "        lambda x: x[0])\n",
    "\n",
    "dfWords3ClustersWithoutStopWords.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfWords3ClustersWithoutStopWords['cluster_value'] = \\\n",
    "    [-1 if i==negativeClusterIndex\n",
    "     else 1 if i==positiveClusterIndex else 0\n",
    "     for i in dfWords3ClustersWithoutStopWords['cluster']]\n",
    "\n",
    "dfWords3ClustersWithoutStopWords['closeness_score'] = \\\n",
    "    dfWords3ClustersWithoutStopWords.apply(\n",
    "        lambda x: 1/(kmeansModel3Clusters.transform([x.vectors]).min()),\n",
    "        axis=1)\n",
    "\n",
    "dfWords3ClustersWithoutStopWords['sentiment_coeff'] = \\\n",
    "    dfWords3ClustersWithoutStopWords['closeness_score'] * \\\n",
    "    dfWords3ClustersWithoutStopWords['cluster_value']\n",
    "\n",
    "dfWords3ClustersWithoutStopWords[\n",
    "    dfWords3ClustersWithoutStopWords['cluster_value'] == -1].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2 Closeness score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dictSentiment3ClustersWithoutStopWords = dict(zip(\n",
    "    dfWords3ClustersWithoutStopWords['words'].values,\n",
    "    dfWords3ClustersWithoutStopWords['sentiment_coeff'].values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "closenessScores3ClustersWithoutStopWords = \\\n",
    "    dfCleanedReviewsWithoutStopWords['comments'].apply(\n",
    "        lambda x: list(map(\n",
    "            lambda y: replace_sentiment_words(y, dictSentiment3ClustersWithoutStopWords),\n",
    "            x.split())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.3 Sentiment score computation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfSentiment3ClustersTfidfReviewsWithoutStopWords = pd.DataFrame(\n",
    "    [closenessScores3ClustersWithoutStopWords,\n",
    "     tfidfScoresWithoutStopWords,\n",
    "     dfCleanedReviewsWithoutStopWords['comments']]).T\n",
    "\n",
    "dfSentiment3ClustersTfidfReviewsWithoutStopWords.columns = \\\n",
    "    ['sentiment_coeff', 'tfidf_scores', 'review']\n",
    "\n",
    "dfSentiment3ClustersTfidfReviewsWithoutStopWords['sentiment_rate'] = \\\n",
    "    dfSentiment3ClustersTfidfReviewsWithoutStopWords.apply(\n",
    "        lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']),\n",
    "        axis=1)\n",
    "\n",
    "dfSentiment3ClustersTfidfReviewsWithoutStopWords['prediction'] = \\\n",
    "    (dfSentiment3ClustersTfidfReviewsWithoutStopWords['sentiment_rate']>0)\\\n",
    "        .astype('int8')\n",
    "\n",
    "dfSentiment3ClustersTfidfReviewsWithoutStopWords.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dfSentiment3ClustersTfidfReviewsWithoutStopWords.to_csv(\n",
    "#     'sentiment_dataset_3_clusters_no_stopwords.csv',\n",
    "#     sep=',', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfNegativeSentiment = dfSentiment3ClustersTfidfReviewsWithoutStopWords[\n",
    "    dfSentiment3ClustersTfidfReviewsWithoutStopWords['prediction'] == 0].sort_values(\n",
    "        by=['sentiment_rate'])\n",
    "\n",
    "dfNegativeSentiment['review'].head().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.4 TextBlob"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfSentiment3ClustersTfidfReviewsWithoutStopWords['textblob_sentiment'] = \\\n",
    "    textblobSentimentWithoutStopWords\n",
    "\n",
    "dfSentiment3ClustersTfidfReviewsWithoutStopWords['textblob_prediction'] = \\\n",
    "    (dfSentiment3ClustersTfidfReviewsWithoutStopWords['textblob_sentiment'] > 0)\\\n",
    "        .astype('int8')\n",
    "\n",
    "dfSentiment3ClustersTfidfReviewsWithoutStopWords.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.5 Sentiment analysis evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testScores3ClustersWithoutStopWordsSentiment = compute_test_scores(\n",
    "    dfSentiment3ClustersTfidfReviewsWithoutStopWords['prediction'],\n",
    "    dfSentiment3ClustersTfidfReviewsWithoutStopWords['textblob_prediction'])\n",
    "\n",
    "dfTestScores3ClustersWithoutStopWordsSentiment = pd.DataFrame(\n",
    "    [testScores3ClustersWithoutStopWordsSentiment])\n",
    "\n",
    "dfTestScores3ClustersWithoutStopWordsSentiment.columns = \\\n",
    "    ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "dfTestScores3ClustersWithoutStopWordsSentiment = \\\n",
    "    dfTestScores3ClustersWithoutStopWordsSentiment.T\n",
    "\n",
    "dfTestScores3ClustersWithoutStopWordsSentiment.columns = ['scores']\n",
    "\n",
    "print('Scores for sentiment analysis with 3 clusters and no stopwords: ')\n",
    "dfTestScores3ClustersWithoutStopWordsSentiment\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The obtained results are strongly worse with respect to the ones that could be\n",
    "expected.\n",
    "It was reasonable to expect a decrease in the accuracy score but not so marked."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import calendar\n",
    "from datetime import date"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Relationships' investigation between price and calendar features\n",
    "\n",
    "This analysis concerns the investigation of some relationships between the price\n",
    "of a room, or listing, and some time periods.\n",
    "In particular, the considered time periods are the days of the week, the seasons\n",
    "of the year and the holidays periods."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.1 Import of the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile('berlin-airbnb-data.zip')\n",
    "dfPricesDates = pd.read_csv(zf.open('calendar_summary.csv'))\n",
    "dfPricesDates.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.2 Columns exploration\n",
    "\n",
    "Once the dataset is imported, it is needed to explore its columns to check whether\n",
    "some data preprocessing technique should be applied.\n",
    "\n",
    "The first step concerns the removal of the null data-points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesDates.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Number of null rows:', dfPricesDates['price'].isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesDates.dropna(axis=0, how='any', inplace=True)\n",
    "dfPricesDates.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the 'available' column only contains a single value, it can be dropped."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesDates['available'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesDates.drop(columns=['available'], inplace=True)\n",
    "dfPricesDates.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to deal with the 'price' column, its values need to be converted into\n",
    "numeric."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type(dfPricesDates['price'].iloc[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesDates['price'] = dfPricesDates['price'].apply(\n",
    "    lambda x: x.replace(',', ''))\n",
    "\n",
    "dfPricesDates['price'] = dfPricesDates['price'].apply(\n",
    "    lambda x: float(x[1:]))\n",
    "\n",
    "dfPricesDates.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, also the type of the 'date' column is converted into datetime."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesDates.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesDates['date'] = pd.to_datetime(dfPricesDates['date'])\n",
    "dfPricesDates.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesDates.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.3 Price vs Day of the week\n",
    "\n",
    "The first step concerns the creation of a new column for the day of the week.\n",
    "In particular, through the use of the calendar library, the week of the day is\n",
    "computed from the corresponding date."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesDates['weekday'] = dfPricesDates.apply(\n",
    "    lambda x: calendar.day_name[x['date'].weekday()], axis=1)\n",
    "\n",
    "dfPricesDates.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, it is possible to show, for each day of the week, the average price of\n",
    "all the listings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weekdayMeans = dfPricesDates.groupby('weekday').price.mean()\n",
    "plt.bar(weekdayMeans.index, weekdayMeans)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A new dataframe is created by computing, for each listing and for each day of the\n",
    "week, the average price."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "listingWeekdayMeans = dfPricesDates.groupby(['listing_id', 'weekday']).price.mean()\n",
    "listingWeekdayMeans.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to work on the dataframe, the days of the week are converted into columns."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfListingWeekdayMeans = listingWeekdayMeans.unstack(level=1)\n",
    "dfListingWeekdayMeans.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, the correlation between the days of the week is computed.\n",
    "In particular, the kendall's tau coefficient is used to measure the correlation\n",
    "degree."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfListingWeekdayMeans.corr(method='kendall')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The correlation matrix shows that all the features are very highly correlated.\n",
    "So, it is possible to state that there are, meanly, very slight differences between\n",
    "the prices of the listings in the different days of the week."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.4 Price vs Season\n",
    "\n",
    "Even in this case, the first step concerns the creation of a new column for the\n",
    "season of the year."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "defaultYear = 2000\n",
    "seasons = [('winter', (date(defaultYear,  1,  1),  date(defaultYear,  3, 20))),\n",
    "           ('spring', (date(defaultYear,  3, 21),  date(defaultYear,  6, 20))),\n",
    "           ('summer', (date(defaultYear,  6, 21),  date(defaultYear,  9, 22))),\n",
    "           ('autumn', (date(defaultYear,  9, 23),  date(defaultYear, 12, 20))),\n",
    "           ('winter', (date(defaultYear, 12, 21),  date(defaultYear, 12, 31)))]\n",
    "\n",
    "def get_season(curr_date):\n",
    "    curr_date = curr_date.replace(year=defaultYear)\n",
    "    return next(season for season, (start, end) in seasons\n",
    "                if start <= curr_date <= end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesDates['season'] = dfPricesDates['date'].apply(\n",
    "    lambda x: get_season(x))\n",
    "\n",
    "dfPricesDates.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, it is possible to show, for each season of the year, the average price of\n",
    "all the listings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seasonMeans = dfPricesDates.groupby('season').price.mean()\n",
    "plt.bar(seasonMeans.index, seasonMeans)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A new dataframe is created by computing, for each listing and for each season of the\n",
    "year, the average price."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "listingSeasonMeans = dfPricesDates.groupby(['listing_id', 'season']).price.mean()\n",
    "listingSeasonMeans.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to work on the dataframe, the seasons of the year are converted into columns."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfListingSeasonMeans = listingSeasonMeans.unstack(level=1)\n",
    "dfListingSeasonMeans.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some listings show NaN values when the mean of the price for a season is considered.\n",
    "This may be caused by the unavailability of the listing during that considered period.\n",
    "So, these listings are not considered in the correlation analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfListingSeasonMeans.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfListingSeasonNonNullMeans = dfListingSeasonMeans.dropna(axis=0, how='any')\n",
    "dfListingSeasonNonNullMeans.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, the correlation between the seasons of the year is computed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfListingSeasonNonNullMeans.corr(method='kendall')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even in this case, the correlation matrix shows that all the features are very highly\n",
    "correlated.\n",
    "So, it is possible to state that there are, meanly, very slight differences between\n",
    "the prices of the listings in the different seasons."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.5 Price vs Holiday\n",
    "\n",
    "Even in this case, the first step concerns the creation of a new column for the\n",
    "holidays.\n",
    "In order to check whether a certain date is considered as holiday, the holidays\n",
    "library is used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import holidays\n",
    "\n",
    "germanHolidays = holidays.Germany()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesDates['holidays'] = dfPricesDates.apply(\n",
    "    lambda x: int(x['date'] in germanHolidays or x['weekday'] == 'Sunday'), axis=1)\n",
    "\n",
    "dfPricesDates.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, it is possible to show, for both the holidays and the non-holidays dates, the\n",
    "average price of all the listings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "holidaysMeans = dfPricesDates.groupby('holidays').price.mean()\n",
    "plt.bar(holidaysMeans.index, holidaysMeans)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A new dataframe is created by computing, for each listing and for both holidays and\n",
    "non-holidays dayes, the average price."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "listingHolidaysMeans = dfPricesDates.groupby(['listing_id', 'holidays']).price.mean()\n",
    "listingHolidaysMeans.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to work on the dataframe, the holidays' values are converted into columns."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfListingHolidaysMeans = listingHolidaysMeans.unstack(level=1)\n",
    "dfListingHolidaysMeans.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some listings show NaN values when the mean of the price for a season is considered.\n",
    "This may be caused by the unavailability of the listing during that considered period.\n",
    "So, these listings are not initially considered in the correlation analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfListingHolidaysMeans.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfListingHolidaysNonNullMeans = dfListingHolidaysMeans.dropna(axis=0, how='any')\n",
    "dfListingHolidaysNonNullMeans.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, the correlation between the holidays and non-holidays dates is computed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfListingHolidaysNonNullMeans.corr(method='kendall')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even in this case, the correlation matrix shows that all the features are very highly\n",
    "correlated.\n",
    "So, it is possible to state that there are, meanly, very slight differences between\n",
    "the prices of the listings in the different days of the week."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Relationships' investigation between price and rooms' characteristics\n",
    "\n",
    "This analysis concerns the investigation of some relationships between the price\n",
    "of a room, or listing, and its own characteristics.\n",
    "Then, the relationships should be used to create a model that is able to make\n",
    "predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.1 Import of the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfListingsSummary = pd.read_csv(zf.open('listings_summary.csv'))\n",
    "dfListingsSummary.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.2 Columns exploration\n",
    "\n",
    "Once the dataset is imported, it is needed to explore its columns to check which\n",
    "of them describe a listing's characteristic."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfListingsSummary.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Firstly, the columns concerning the room characteristics and the prices are selected."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypes = dfListingsSummary[['id', 'room_type', 'accommodates',\n",
    "                                          'bathrooms', 'bedrooms', 'beds', 'bed_type',\n",
    "                                          'amenities', 'square_feet', 'price',\n",
    "                                          'weekly_price', 'monthly_price',\n",
    "                                          'security_deposit', 'cleaning_fee']]\n",
    "\n",
    "dfPricesListingTypes.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypes.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the null data-points, the columns 'square_feet', 'weekly_price',\n",
    "'monthly_price', 'security_deposit' and 'cleaning_fee' can be dropped."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypes = dfPricesListingTypes.drop(\n",
    "    columns=['square_feet', 'weekly_price', 'monthly_price', 'security_deposit',\n",
    "             'cleaning_fee'])\n",
    "\n",
    "dfPricesListingTypes.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since it is not needed in order to make predictions, the column 'id' is dropped."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypes = dfPricesListingTypes.drop(columns=['id'])\n",
    "dfPricesListingTypes.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The column 'price' must be converted into numeric."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypes['price'] = dfPricesListingTypes['price'].apply(\n",
    "    lambda x: x.replace(',', ''))\n",
    "\n",
    "dfPricesListingTypes['price'] = dfPricesListingTypes['price'].apply(\n",
    "    lambda x: float(x[1:]))\n",
    "\n",
    "dfPricesListingTypes.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instead of directly dealing with the column 'amenities', it can be replaced\n",
    "by the number of amenities each listing contains."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypes['amenities'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypes['amenities_nr'] = dfPricesListingTypes.apply(\n",
    "    lambda x: len(x['amenities'].split(',')) + 1, axis=1)\n",
    "\n",
    "dfPricesListingTypes = dfPricesListingTypes.drop(columns=['amenities'])\n",
    "\n",
    "dfPricesListingTypes.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to deal with the column 'room_type', the corresponding dummies are generated\n",
    "and inserted into the dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dummiesRoomType = pd.get_dummies(dfPricesListingTypes['room_type'])\n",
    "dummiesRoomType.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypes = dfPricesListingTypes.drop(columns=['room_type'])\n",
    "dfPricesListingTypes = pd.concat([dfPricesListingTypes, dummiesRoomType], axis=1)\n",
    "dfPricesListingTypes.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to deal with the column 'bed_type', the corresponding dummies are generated\n",
    "and inserted into the dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dummiesBedType = pd.get_dummies(dfPricesListingTypes['bed_type'])\n",
    "dummiesBedType.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypes = dfPricesListingTypes.drop(columns=['bed_type'])\n",
    "dfPricesListingTypes = pd.concat([dfPricesListingTypes, dummiesBedType], axis=1)\n",
    "dfPricesListingTypes.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, the data-points containing null points must be removed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypes.dropna(axis=0, how='any', inplace=True)\n",
    "dfPricesListingTypes.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.3 Outliers analysis\n",
    "\n",
    "Another important step concerns the analysis of the column 'price' in order to check\n",
    "whether it contains some outliers.\n",
    "\n",
    "Firstly, the heatmap concerning the correlation between the selected columns is shown."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(df):\n",
    "    sns.set(font_scale = 1.4)\n",
    "    plt.figure(figsize = (18,18))\n",
    "    sns.heatmap(df.corr(method='kendall'),\n",
    "                cmap=plt.cm.Blues,\n",
    "                annot = True)\n",
    "    plt.gca().set_title('Price VS Listing characteristics', fontsize = 15)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_correlation_matrix(dfPricesListingTypes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "According to the heatmap, the column 'price' shows a slight degree of correlation with\n",
    "only a few columns in the dataframe.\n",
    "In particular, it shows slight positive correlation with both 'accommodates' and\n",
    "'Entire home/apt', and a slight negative correlation with 'Private room'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.boxplot(x=dfPricesListingTypes['price'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The boxplot shows the existence of some outliers.\n",
    "\n",
    "So, basing on the mean and the standard deviation values, two border limits are\n",
    "computed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_outliers_limits(df_column, factor):\n",
    "    upper_lim = df_column.mean () + df_column.std () * factor\n",
    "\n",
    "    lower_lim = df_column.mean () - df_column.std () * factor\n",
    "\n",
    "    return upper_lim, lower_lim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "upperLim, lowerLim = get_outliers_limits(dfPricesListingTypes['price'], 3)\n",
    "\n",
    "print(\"upper_lim:\", upperLim)\n",
    "print(\"lower_lim:\", lowerLim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the values in the column 'price' are always positive, the lower limit can be\n",
    "discarded."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypesWithoutOutliers = \\\n",
    "    dfPricesListingTypes[dfPricesListingTypes['price'] < upperLim]\n",
    "\n",
    "print('Number of outliers removed:',\n",
    "      dfPricesListingTypes.shape[0] - dfPricesListingTypesWithoutOutliers.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.boxplot(x=dfPricesListingTypesWithoutOutliers['price'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.4 Regression\n",
    "\n",
    "In order to make predictions on the column 'price', a regression model can be\n",
    "built-up."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.4.1 Regression with numerical features\n",
    "\n",
    "Firstly, it is possible to start building the regression model by using just the\n",
    "features that were initially provided as numerical."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesNumericalListingTypes = \\\n",
    "    dfPricesListingTypesWithoutOutliers[['accommodates', 'bathrooms', 'bedrooms',\n",
    "                                         'beds', 'price']]\n",
    "\n",
    "dfPricesNumericalListingTypes.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the numerical features are selected, the heatmap concerning the correlation\n",
    "between them can be shown."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_correlation_matrix(dfPricesNumericalListingTypes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before the creation of the regression model, the available data-points should be\n",
    "split into train and test data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_train_test(train_data, test_data):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(\n",
    "        train_data, test_data, test_size=0.3, shuffle=True, random_state=42)\n",
    "\n",
    "    return train_x, test_x, train_y, test_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainXNumerical, testXNumerical, trainYNumerical, testYNumerical = \\\n",
    "    get_train_test(dfPricesNumericalListingTypes.iloc[:,:4],\n",
    "                   dfPricesNumericalListingTypes['price'])\n",
    "\n",
    "trainXNumerical.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the data has been split, a linear regression model can be built-up and trained."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linearRegressionNumerical = linear_model.LinearRegression()\n",
    "linearRegressionNumerical.fit(trainXNumerical, trainYNumerical)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, the values concerning the model coefficients and the model accuracy can be\n",
    "shown.\n",
    "The score coefficient, representing the accuracy of the model, is the coefficient\n",
    "of determination R^2 of the prediction.\n",
    "It is computed as\n",
    "\n",
    "$$ R^2 = 1 - u/v $$\n",
    "\n",
    "where u is the residual sum of squares and v is the total sum of squares."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Coefficients:', linearRegressionNumerical.coef_)\n",
    "print('Intercept:', linearRegressionNumerical.intercept_)\n",
    "print('Score:', linearRegressionNumerical.score(testXNumerical, testYNumerical))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the score, the regression model does not reach a good value of accuracy.\n",
    "\n",
    "It is also possible to plot both the training and the test errors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_regression_error(regression_model, train_x, train_y, test_x, test_y):\n",
    "\n",
    "    ## plotting residual errors in training data\n",
    "    plt.scatter(regression_model.predict(train_x),\n",
    "                regression_model.predict(train_x) - train_y,\n",
    "                color = \"green\", s = 10, label = 'Train data')\n",
    "\n",
    "    ## plotting residual errors in test data\n",
    "    plt.scatter(regression_model.predict(test_x),\n",
    "                regression_model.predict(test_x) - test_y,\n",
    "                color = \"blue\", s = 10, label = 'Test data')\n",
    "\n",
    "    ## plotting legend\n",
    "    plt.legend(loc = 'upper right')\n",
    "\n",
    "    ## plot title\n",
    "    plt.title(\"Residual errors\")\n",
    "\n",
    "    ## method call for showing the plot\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_regression_error(linearRegressionNumerical, trainXNumerical, trainYNumerical,\n",
    "                      testXNumerical, testYNumerical)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.4.2 Regression with all the features\n",
    "\n",
    "Looking at the results obtained by using only the numerical features, it is possible\n",
    "to build the regression model with all the features.\n",
    "\n",
    "The performed steps are the same as before."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesAllListingTypes = dfPricesListingTypesWithoutOutliers.copy()\n",
    "dfPricesAllListingTypes.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_correlation_matrix(dfPricesAllListingTypes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = get_train_test(\n",
    "    dfPricesAllListingTypes.loc[\n",
    "        :, dfPricesAllListingTypes.columns != 'price'],\n",
    "    dfPricesAllListingTypes['price'])\n",
    "\n",
    "trainX.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linearRegression = linear_model.LinearRegression()\n",
    "linearRegression.fit(trainX, trainY)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Coefficients:', linearRegression.coef_)\n",
    "print('Intercept:', linearRegression.intercept_)\n",
    "print('Score:', linearRegression.score(testX, testY))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the score, the regression model reaches a better value of accuracy,\n",
    "but even in this case the results are not satisfactory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_regression_error(linearRegression, trainX, trainY, testX, testY)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.5 Classification\n",
    "\n",
    "Instead of trying to predict the column 'price' with a regression, it is also\n",
    "possible to transform it into a categorical feature and try to predict the\n",
    "category."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.5.1 Transformation of price for classification\n",
    "\n",
    "The 'price' feature needs to be binned in order to generate categorical values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesAllListingTypes['price'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to obtain an optimized binning of the feature, a clustering technique\n",
    "on the feature is used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans_elbow_method(dfPricesAllListingTypes['price'].values.reshape(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rangeClusters = enumerate([2,3,4,5])\n",
    "kmeans_silhouette(dfPricesAllListingTypes['price'].values.reshape(-1,1), rangeClusters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The value n_clusters = 3 is chosen because it allows to have a more flexible\n",
    "classification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeansModelPrice = KMeans(n_clusters=3, max_iter=1000, random_state=42, n_init=50)\n",
    "kmeansModelPrice.fit(dfPricesAllListingTypes['price'].values.reshape(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeansModelPrice.cluster_centers_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the model clusters, it is possible to assign the cluster index to\n",
    "each binning value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lowClusterIndex = 1\n",
    "mediumClusterIndex = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.5.2 Classification with numerical features\n",
    "\n",
    "Firstly, it is possible to start building the classification model by using just the\n",
    "features that were initially provided as numerical."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesNumericalListingTypes['price_cluster'] = kmeansModelPrice.predict(\n",
    "    dfPricesNumericalListingTypes['price'].values.reshape(-1,1))\n",
    "\n",
    "dfPricesNumericalListingTypes['price_cluster'] = \\\n",
    "    dfPricesNumericalListingTypes['price_cluster'].apply(\n",
    "        lambda x: 'low' if x==lowClusterIndex else\n",
    "            'medium' if x==mediumClusterIndex else 'high')\n",
    "\n",
    "dfPricesNumericalListingTypes.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before the creation of the classification model, the available data-points should be\n",
    "split into train and test data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainXNumericalClass, testXNumericalClass, trainYNumericalClass, testYNumericalClass = \\\n",
    "    get_train_test(dfPricesNumericalListingTypes.iloc[:,:4],\n",
    "                   dfPricesNumericalListingTypes['price_cluster'])\n",
    "\n",
    "trainXNumericalClass.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the data has been split, a decision tree classifier can be built-up and trained."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decisionTreeNumerical = DecisionTreeClassifier()\n",
    "decisionTreeNumerical.fit(trainXNumericalClass, trainYNumericalClass)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, the model is used in order to generate the predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictionsNumerical = decisionTreeNumerical.predict(testXNumericalClass)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the predictions have been generated, it is possible to evaluate the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(confusion_matrix(testYNumericalClass, predictionsNumerical))\n",
    "print(classification_report(testYNumericalClass, predictionsNumerical))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The classification with only the numerical features globally shows good results, with\n",
    "an accuracy of 78%.\n",
    "In particular, the model shows very good values for the \"low\" classification, but poor\n",
    "results in the classification of \"medium\" and \"high\" data-points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.5.3 Classification with all the features\n",
    "\n",
    "Looking at the results obtained by using only the numerical features, it is possible\n",
    "to build the classification model with all the features.\n",
    "\n",
    "The performed steps are the same as before."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesAllListingTypes['price_cluster'] = kmeansModelPrice.predict(\n",
    "    dfPricesAllListingTypes['price'].values.reshape(-1,1))\n",
    "\n",
    "dfPricesAllListingTypes['price_cluster'] = \\\n",
    "    dfPricesAllListingTypes['price_cluster'].apply(\n",
    "        lambda x: 'low' if x==lowClusterIndex else\n",
    "            'medium' if x==mediumClusterIndex else 'high')\n",
    "\n",
    "dfPricesAllListingTypes.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainXClass, testXClass, trainYClass, testYClass = get_train_test(\n",
    "    dfPricesAllListingTypes.drop(columns=['price', 'price_cluster']),\n",
    "    dfPricesAllListingTypes['price_cluster'])\n",
    "\n",
    "trainXClass.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decisionTree = DecisionTreeClassifier()\n",
    "decisionTree.fit(trainXClass, trainYClass)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = decisionTree.predict(testXClass)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(confusion_matrix(testYClass, predictions))\n",
    "print(classification_report(testYClass, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even in this case, the classification with all the features globally shows some\n",
    "good results, that are only slightly lower than using only the numerical features.\n",
    "In particular, the model shows a global accuracy of 76%, very good values for the\n",
    "\"low\" classification, but poor results in the classification of \"medium\" and \"high\"\n",
    "data-points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.6 Outliers removal with new threshold\n",
    "\n",
    "Since the previously-obtained results are not very satisfactory, it is possible to\n",
    "increase the number of removed outliers.\n",
    "This operation is performed by increasing the multiplication factor in the formula\n",
    "used to obtain the border limits."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "upperLim2, lowerLim2 = get_outliers_limits(dfPricesListingTypes['price'], 2)\n",
    "\n",
    "print(\"upper_lim:\", upperLim2)\n",
    "print(\"lower_lim:\", lowerLim2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the values in the column 'price' are always positive, the lower limit can be\n",
    "discarded."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypesWithoutOutliers2 = \\\n",
    "    dfPricesListingTypes[dfPricesListingTypes['price'] < upperLim2]\n",
    "\n",
    "print('Number of outliers removed:',\n",
    "      dfPricesListingTypes.shape[0] - dfPricesListingTypesWithoutOutliers2.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.boxplot(x=dfPricesListingTypesWithoutOutliers2['price'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.6.1 Regression with numerical features and new threshold\n",
    "\n",
    "The performed steps are always the same."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesNumericalListingTypes2 = \\\n",
    "    dfPricesListingTypesWithoutOutliers2[['accommodates', 'bathrooms', 'bedrooms',\n",
    "                                         'beds', 'price']]\n",
    "\n",
    "dfPricesNumericalListingTypes2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_correlation_matrix(dfPricesNumericalListingTypes2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainXNumerical2, testXNumerical2, trainYNumerical2, testYNumerical2 = \\\n",
    "    get_train_test(dfPricesNumericalListingTypes2.iloc[:,:4],\n",
    "                   dfPricesNumericalListingTypes2['price'])\n",
    "\n",
    "trainXNumerical2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linearRegressionNumerical2 = linear_model.LinearRegression()\n",
    "linearRegressionNumerical2.fit(trainXNumerical2, trainYNumerical2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Coefficients:', linearRegressionNumerical2.coef_)\n",
    "print('Intercept:', linearRegressionNumerical2.intercept_)\n",
    "print('Score:', linearRegressionNumerical2.score(testXNumerical2, testYNumerical2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With respect to the results obtained by using more data-points, the model accuracy\n",
    "is slightly increased.\n",
    "However, the results are still not satisfactory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_regression_error(linearRegressionNumerical2, trainXNumerical2, trainYNumerical2,\n",
    "                      testXNumerical2, testYNumerical2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.6.2 Regression with all the features and new threshold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesAllListingTypes2 = dfPricesListingTypesWithoutOutliers2.copy()\n",
    "dfPricesAllListingTypes2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_correlation_matrix(dfPricesAllListingTypes2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainX2, testX2, trainY2, testY2 = get_train_test(\n",
    "    dfPricesAllListingTypes2.loc[\n",
    "        :, dfPricesAllListingTypes2.columns != 'price'],\n",
    "    dfPricesAllListingTypes2['price'])\n",
    "\n",
    "trainX2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linearRegression2 = linear_model.LinearRegression()\n",
    "linearRegression2.fit(trainX2, trainY2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Coefficients:', linearRegression2.coef_)\n",
    "print('Intercept:', linearRegression2.intercept_)\n",
    "print('Score:', linearRegression2.score(testX2, testY2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even in this case, the accuracy value is slightly greater than the one obtained\n",
    "by considering a higher number of data-points, but still not enough in order to\n",
    "make reliable predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_regression_error(linearRegression2, trainX2, trainY2, testX2, testY2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.6.3 Transformation of price with new threshold for classification\n",
    "\n",
    "It is also possible to use the dataframe with more outliers removed in order to\n",
    "create a new classification model and check its performance.\n",
    "\n",
    "Even in this case, the performed steps are always the same."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesAllListingTypes2['price'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans_elbow_method(dfPricesAllListingTypes2['price'].values.reshape(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rangeClusters = enumerate([2,3,4,5])\n",
    "kmeans_silhouette(dfPricesAllListingTypes2['price'].values.reshape(-1,1),\n",
    "                  rangeClusters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The value n_clusters = 3 is chosen because it allows to have a more flexible\n",
    "classification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeansModelPrice2 = KMeans(n_clusters=3, max_iter=1000, random_state=42, n_init=50)\n",
    "kmeansModelPrice2.fit(dfPricesAllListingTypes2['price'].values.reshape(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeansModelPrice2.cluster_centers_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lowClusterIndex2 = 0\n",
    "mediumClusterIndex2 = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.6.4 Classification with numerical features and new threshold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesNumericalListingTypes2['price_cluster'] = kmeansModelPrice2.predict(\n",
    "    dfPricesNumericalListingTypes2['price'].values.reshape(-1,1))\n",
    "\n",
    "dfPricesNumericalListingTypes2['price_cluster'] = \\\n",
    "    dfPricesNumericalListingTypes2['price_cluster'].apply(\n",
    "        lambda x: 'low' if x==lowClusterIndex2 else\n",
    "            'medium' if x==mediumClusterIndex2 else 'high')\n",
    "\n",
    "dfPricesNumericalListingTypes2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainXNumericalClass2, testXNumericalClass2, trainYNumericalClass2, testYNumericalClass2 = \\\n",
    "    get_train_test(dfPricesNumericalListingTypes2.iloc[:,:4],\n",
    "                   dfPricesNumericalListingTypes2['price_cluster'])\n",
    "\n",
    "trainXNumericalClass2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decisionTreeNumerical2 = DecisionTreeClassifier()\n",
    "decisionTreeNumerical2.fit(trainXNumericalClass2, trainYNumericalClass2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictionsNumerical2 = decisionTreeNumerical2.predict(testXNumericalClass2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(confusion_matrix(testYNumericalClass2, predictionsNumerical2))\n",
    "print(classification_report(testYNumericalClass2, predictionsNumerical2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even in this case, the classification with only the numerical features globally\n",
    "shows good results, with an accuracy of 78%.\n",
    "The results are comparable to the ones previously-obtained."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.6.5 Classification with all the features and new threshold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesAllListingTypes2['price_cluster'] = kmeansModelPrice2.predict(\n",
    "    dfPricesAllListingTypes2['price'].values.reshape(-1,1))\n",
    "\n",
    "dfPricesAllListingTypes2['price_cluster'] = \\\n",
    "    dfPricesAllListingTypes2['price_cluster'].apply(\n",
    "        lambda x: 'low' if x==lowClusterIndex2 else\n",
    "            'medium' if x==mediumClusterIndex2 else 'high')\n",
    "\n",
    "dfPricesAllListingTypes2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainXClass2, testXClass2, trainYClass2, testYClass2 = get_train_test(\n",
    "    dfPricesAllListingTypes2.drop(columns=['price', 'price_cluster']),\n",
    "    dfPricesAllListingTypes2['price_cluster'])\n",
    "\n",
    "trainXClass2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decisionTree2 = DecisionTreeClassifier()\n",
    "decisionTree2.fit(trainXClass2, trainYClass2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions2 = decisionTree2.predict(testXClass2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(confusion_matrix(testYClass2, predictions2))\n",
    "print(classification_report(testYClass2, predictions2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even in this case, the classification accuracy is comparable to the one obtained\n",
    "by using the dataframe containing more data-points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.7 Outliers removal with percentiles\n",
    "\n",
    "The outliers can also be removed according to the percentiles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "upperLim3 = dfPricesListingTypes['price'].quantile(.99) # Return value at the given quantile\n",
    "lowerLim3 = dfPricesListingTypes['price'].quantile(.01)\n",
    "\n",
    "print(\"upper_lim:\", upperLim3)\n",
    "print(\"lower_lim:\", lowerLim3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypesWithoutOutliers3 = \\\n",
    "    dfPricesListingTypes[dfPricesListingTypes['price'] > lowerLim3]\n",
    "\n",
    "dfPricesListingTypesWithoutOutliers3 = dfPricesListingTypesWithoutOutliers3[\n",
    "    dfPricesListingTypesWithoutOutliers3['price'] < upperLim3]\n",
    "\n",
    "print('Number of outliers removed:',\n",
    "      dfPricesListingTypes.shape[0] - dfPricesListingTypesWithoutOutliers3.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.boxplot(x=dfPricesListingTypesWithoutOutliers3['price'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.7.1 Regression with numerical features and percentiles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesNumericalListingTypes3 = \\\n",
    "    dfPricesListingTypesWithoutOutliers3[['accommodates', 'bathrooms', 'bedrooms',\n",
    "                                         'beds', 'price']]\n",
    "\n",
    "dfPricesNumericalListingTypes3.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_correlation_matrix(dfPricesNumericalListingTypes3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainXNumerical3, testXNumerical3, trainYNumerical3, testYNumerical3 = \\\n",
    "    get_train_test(dfPricesNumericalListingTypes3.iloc[:,:4],\n",
    "                   dfPricesNumericalListingTypes3['price'])\n",
    "\n",
    "trainXNumerical3.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linearRegressionNumerical3 = linear_model.LinearRegression()\n",
    "linearRegressionNumerical3.fit(trainXNumerical3, trainYNumerical3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Coefficients:', linearRegressionNumerical3.coef_)\n",
    "print('Intercept:', linearRegressionNumerical3.intercept_)\n",
    "print('Score:', linearRegressionNumerical3.score(testXNumerical3, testYNumerical3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With respect to the results obtained by the previous analysis, the model accuracy\n",
    "is slightly increased.\n",
    "However, the results are still not satisfactory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_regression_error(linearRegressionNumerical3, trainXNumerical3, trainYNumerical3,\n",
    "                      testXNumerical3, testYNumerical3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.7.2 Regression with all the features and percentiles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesAllListingTypes3 = dfPricesListingTypesWithoutOutliers3.copy()\n",
    "dfPricesAllListingTypes3.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_correlation_matrix(dfPricesAllListingTypes3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainX3, testX3, trainY3, testY3 = get_train_test(\n",
    "    dfPricesAllListingTypes3.loc[\n",
    "        :, dfPricesAllListingTypes3.columns != 'price'],\n",
    "    dfPricesAllListingTypes3['price'])\n",
    "\n",
    "trainX3.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linearRegression3 = linear_model.LinearRegression()\n",
    "linearRegression3.fit(trainX3, trainY3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Coefficients:', linearRegression3.coef_)\n",
    "print('Intercept:', linearRegression3.intercept_)\n",
    "print('Score:', linearRegression3.score(testX3, testY3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even in this case, the accuracy results are slightly better than the one obtained\n",
    "in the previous analysis.\n",
    "However, they are still not good enough in order to make reliable predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_regression_error(linearRegression3, trainX3, trainY3, testX3, testY3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.7.3 Transformation of price with percentiles for classification\n",
    "\n",
    "The 'price' feature is binned in order to generate categorical values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesAllListingTypes3['price'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans_elbow_method(dfPricesAllListingTypes3['price'].values.reshape(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rangeClusters = enumerate([2,3,4,5])\n",
    "kmeans_silhouette(dfPricesAllListingTypes3['price'].values.reshape(-1,1),\n",
    "                  rangeClusters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The value n_clusters = 3 is chosen because it allows to have a more flexible\n",
    "classification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeansModelPrice3 = KMeans(n_clusters=3, max_iter=1000, random_state=42, n_init=50)\n",
    "kmeansModelPrice3.fit(dfPricesAllListingTypes3['price'].values.reshape(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeansModelPrice3.cluster_centers_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lowClusterIndex3 = 0\n",
    "mediumClusterIndex3 = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.7.4 Classification with numerical features and percentiles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesNumericalListingTypes3['price_cluster'] = kmeansModelPrice3.predict(\n",
    "    dfPricesNumericalListingTypes3['price'].values.reshape(-1,1))\n",
    "\n",
    "dfPricesNumericalListingTypes3['price_cluster'] = \\\n",
    "    dfPricesNumericalListingTypes3['price_cluster'].apply(\n",
    "        lambda x: 'low' if x==lowClusterIndex3 else\n",
    "            'medium' if x==mediumClusterIndex3 else 'high')\n",
    "\n",
    "dfPricesNumericalListingTypes3.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainXNumericalClass3, testXNumericalClass3, trainYNumericalClass3, testYNumericalClass3 = \\\n",
    "    get_train_test(dfPricesNumericalListingTypes3.iloc[:,:4],\n",
    "                   dfPricesNumericalListingTypes3['price_cluster'])\n",
    "\n",
    "trainXNumericalClass3.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decisionTreeNumerical3 = DecisionTreeClassifier()\n",
    "decisionTreeNumerical3.fit(trainXNumericalClass3, trainYNumericalClass3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictionsNumerical3 = decisionTreeNumerical3.predict(testXNumericalClass3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(confusion_matrix(testYNumericalClass3, predictionsNumerical3))\n",
    "print(classification_report(testYNumericalClass3, predictionsNumerical3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even in this case, the classification with only the numerical features globally\n",
    "shows good results, with an accuracy of 71%.\n",
    "The results are slightly worse than the ones obtained in the previous analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.7.5 Classification with all the features and percentiles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesAllListingTypes3['price_cluster'] = kmeansModelPrice3.predict(\n",
    "    dfPricesAllListingTypes3['price'].values.reshape(-1,1))\n",
    "\n",
    "dfPricesAllListingTypes3['price_cluster'] = \\\n",
    "    dfPricesAllListingTypes3['price_cluster'].apply(\n",
    "        lambda x: 'low' if x==lowClusterIndex3 else\n",
    "            'medium' if x==mediumClusterIndex3 else 'high')\n",
    "\n",
    "dfPricesAllListingTypes3.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainXClass3, testXClass3, trainYClass3, testYClass3 = get_train_test(\n",
    "    dfPricesAllListingTypes3.drop(columns=['price', 'price_cluster']),\n",
    "    dfPricesAllListingTypes3['price_cluster'])\n",
    "\n",
    "trainXClass3.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decisionTree3 = DecisionTreeClassifier()\n",
    "decisionTree3.fit(trainXClass3, trainYClass3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions3 = decisionTree3.predict(testXClass3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(confusion_matrix(testYClass3, predictions3))\n",
    "print(classification_report(testYClass3, predictions3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even in this case, the classification with all the features globally shows good\n",
    "results, with an accuracy of 71%.\n",
    "The results are slightly worse than the ones obtained in the previous analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.8 Classification with balanced classes\n",
    "\n",
    "Since all the classification reports have shown that the considered classes are\n",
    "strongly unbalanced, it is possible to try to perform a balancing operation.\n",
    "In this way, the classification model should be able to better predict the labels\n",
    "of the classes that were initially represented by a lower number of samples."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.8.1 Dataframe balancing\n",
    "\n",
    "The starting dataframe is the one from which the best classification model has\n",
    "been built-up, that is the dataframe from which the outliers removal operation was\n",
    "based on the mean and the standard deviation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypesUnbalanced = dfPricesNumericalListingTypes.copy()\n",
    "dfPricesListingTypesUnbalanced.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypesUnbalanced.groupby('price_cluster').price.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to balance the classes, the data-points with label 'high' need to be\n",
    "over-sampled, while the data-points with label 'low' need to be under-sampled.\n",
    "The desired number of data-points for each label of 'price_cluster' is the number\n",
    "of data-points with the label 'medium'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def over_sample(df, label, length):\n",
    "    df_label = df[df['price_cluster'] == label]\n",
    "    df_label_oversampled = resample(df_label, replace=True,\n",
    "                                    n_samples=length, random_state=42)\n",
    "\n",
    "    return df_label_oversampled\n",
    "\n",
    "def under_sample(df, label, length):\n",
    "    df_label = df[df['price_cluster'] == label]\n",
    "    df_label_undersampled = df_label.sample(n=length)\n",
    "\n",
    "    return df_label_undersampled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_balanced_df(df):\n",
    "    df_medium_price_cluster_balanced = df[df['price_cluster'] == 'medium']\n",
    "\n",
    "    df_low_price_cluster_balanced = \\\n",
    "        under_sample(df, 'low', df_medium_price_cluster_balanced.shape[0])\n",
    "\n",
    "    df_high_price_cluster_balanced = \\\n",
    "        over_sample(df, 'high', df_medium_price_cluster_balanced.shape[0])\n",
    "\n",
    "    return pd.concat([df_low_price_cluster_balanced,\n",
    "                      df_medium_price_cluster_balanced,\n",
    "                      df_high_price_cluster_balanced])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypesBalanced = create_balanced_df(dfPricesListingTypesUnbalanced)\n",
    "dfPricesListingTypesBalanced.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfPricesListingTypesBalanced.groupby('price_cluster').price.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.8.2 Classification with balanced dataframe\n",
    "\n",
    "Once the balanced dataframe is available, it is possible to perform a new\n",
    "classification experiment.\n",
    "\n",
    "The performed steps are always the same."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainXBalancedClass, testXBalancedClass, trainYBalancedClass, testYBalancedClass = \\\n",
    "    get_train_test(dfPricesListingTypesBalanced.iloc[:,:4],\n",
    "                   dfPricesListingTypesBalanced['price_cluster'])\n",
    "\n",
    "trainXBalancedClass.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decisionTreeBalanced = DecisionTreeClassifier()\n",
    "decisionTreeBalanced.fit(trainXBalancedClass, trainYBalancedClass)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictionsBalanced = decisionTreeBalanced.predict(testXBalancedClass)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(confusion_matrix(testYBalancedClass, predictionsBalanced))\n",
    "print(classification_report(testYBalancedClass, predictionsBalanced))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the balanced classes, the model shows precision and recall values that are\n",
    "better with respect to the other classification models.\n",
    "However, the global accuracy of the model is around 10% lower with respect to\n",
    "the other ones."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9. Conclusions\n",
    "\n",
    "The final considerations about the performed analysis can be reported."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9.1 Sentiment analysis\n",
    "\n",
    "Concerning the sentiment analysis, the obtained results show that it is possible to\n",
    "reach an accuracy value that is very close to the one obtained by an already-existing\n",
    "external library.\n",
    "In particular, these results have been reached through the use of many pre-processing\n",
    "techniques, such as the tokenization of the reviews, the normalization of the words\n",
    "and removal of the stop words.\n",
    "Furthermore, the use of the Word2Vec technique, combined with both the clustering\n",
    "for the detection of the sentiment of each word, and the TF-IDF technique for the\n",
    "weight of the words inside each review, has shown very good results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9.2 Correlation analysis\n",
    "\n",
    "Concerning the correlation analysis performed over the feature 'price', the obtained\n",
    "results are not very satisfactory.\n",
    "\n",
    "In particular, concerning the correlation between the 'price' and the calendar\n",
    "features, the correlation matrices have always shown a very high correlation between\n",
    "the average price of the listings and the different values of the calendar features.\n",
    "In only one case, indeed, it is possible to notice a correlation value that is lower\n",
    "than 0.9.\n",
    "This case concerns the correlation of the average price during the 'winter' and the\n",
    "'summer' seasons, and they show a correlation value of 0.89.\n",
    "\n",
    "So, it is not possible to identify some correlation relationships between the 'price'\n",
    "of a room and the considered calendar features.\n",
    "\n",
    "Concerning the correlation between the 'price' and the room's characteristics, the\n",
    "initial dataframe shows a weak correlation between the 'price' and all the considered\n",
    "features.\n",
    "After the outliers removal operation, the correlation values have not changed\n",
    "significantly, and the effects can be noticed in the accuracy values of the generated\n",
    "models.\n",
    "In particular, the best regression model is built-up by considering all the features\n",
    "after the outliers removal operation with the percentiles, and its accuracy score is\n",
    "0.45.\n",
    "The best classification model is built-up by only considering the numerical features\n",
    "after the outliers removal operation based on the mean and the standard deviation,\n",
    "and it reaches an accuracy value of 0.78.\n",
    "Even trying to balance the classes, the classification accuracy has not shown \n",
    "good values, with a global score of 0.67.\n",
    "\n",
    "So, it is not possible to predict with a good confidence the price of a room given\n",
    "its characteristics.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}